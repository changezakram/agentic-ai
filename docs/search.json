[
  {
    "objectID": "gen-bi-vs-agentic-analytics.html",
    "href": "gen-bi-vs-agentic-analytics.html",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "",
    "text": "This guide explains the difference between Generative BI (Gen BI) and Agentic Analytics, with examples, use cases, roadmap, and example architectures."
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#overview",
    "href": "gen-bi-vs-agentic-analytics.html#overview",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "",
    "text": "This guide explains the difference between Generative BI (Gen BI) and Agentic Analytics, with examples, use cases, roadmap, and example architectures."
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#whats-the-difference",
    "href": "gen-bi-vs-agentic-analytics.html#whats-the-difference",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "2 ğŸ”· Whatâ€™s the difference?",
    "text": "2 ğŸ”· Whatâ€™s the difference?\n\n\n\n\n\n\n\n\nFeature\nGenerative BI\nAgentic Analytics\n\n\n\n\nDefinition\nUse of generative AI (e.g., LLMs) to make BI conversational and accessible\nUse of autonomous AI agents to monitor, reason, and act\n\n\nFocus\nNatural language querying & insight generation\nAutonomous problem-solving & action-taking\n\n\nUser Role\nUser asks â†’ system answers\nAgent acts â†’ user reviews/overrides\n\n\nTech Foundation\nLLMs, NLP, vector search\nAgents, reasoning, orchestration, planning\n\n\nGoal\nDemocratize data insights\nProactively optimize KPIs & take actions"
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#examples",
    "href": "gen-bi-vs-agentic-analytics.html#examples",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "3 ğŸŒŸ Examples",
    "text": "3 ğŸŒŸ Examples\n\n3.1 Generative BI\nâœ… User asks: â€œShow me revenue trends by region last quarter.â€\nâœ… NLP translates â†’ SQL â†’ dashboard or insight.\nâœ… Tools: Microsoft Copilot in Power BI, Tableau GPT, ThoughtSpot Sage, Looker.\n\n\n3.2 Agentic Analytics\nâœ… Agent monitors churn â†’ detects anomaly â†’ runs analysis â†’ recommends retention campaign â†’ optionally triggers it.\nâœ… Tools: LangChain Agents, AutoGen, CrewAI, IBM Watson Decision Support."
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#use-cases-in-banking",
    "href": "gen-bi-vs-agentic-analytics.html#use-cases-in-banking",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "4 ğŸ¦ Use Cases in Banking",
    "text": "4 ğŸ¦ Use Cases in Banking\n\n\n\n\n\n\n\nGenerative BI\nAgentic Analytics\n\n\n\n\nSelf-service dashboards and reports\nContinuous KPI monitoring and autonomous adjustment\n\n\nNatural-language queries on deposits, loans, churn\nDetects anomalies and launches root cause analysis\n\n\nAutomated dashboards and narratives\nAdjusts operations or triggers workflows autonomously"
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#roadmap-maturity-journey",
    "href": "gen-bi-vs-agentic-analytics.html#roadmap-maturity-journey",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "5 ğŸ“ˆ Roadmap: Maturity Journey",
    "text": "5 ğŸ“ˆ Roadmap: Maturity Journey\n\n\n\n\n\n\n\n\nStage\nDescription\nExample Outcome\n\n\n\n\n1. Traditional BI\nStatic dashboards\nâ€œI can see my KPIs weekly.â€\n\n\n2. Self-Service BI\nBusiness users build own reports\nâ€œI can slice & dice myself.â€\n\n\n3. Generative BI\nNLP-driven, automated insights\nâ€œI can ask anything & get answers.â€\n\n\n4. Augmented BI\nSystem suggests anomalies/trends\nâ€œIt highlights what matters.â€\n\n\n5. Agentic Analytics\nAgents monitor & act autonomously\nâ€œIt adjusts operations proactively.â€"
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#example-architectures",
    "href": "gen-bi-vs-agentic-analytics.html#example-architectures",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "6 ğŸªœ Example Architectures",
    "text": "6 ğŸªœ Example Architectures\n\n6.1 Generative BI\n[User]\n   â†“\n[LLM/NLP]\n   â†“\n[Semantic Layer + SQL Generator]\n   â†“\n[Data Warehouse]\n   â†“\n[BI Tool / Dashboard]\n\n\n\n6.2 Agentic Analytics\n               [Agent Framework]\n                     â†“\n   [Planner + Reasoner + Memory + Tools]\n                     â†“\n [Data Warehouse + Real-time Streams]\n                     â†“\n [BI Tools] & [Action APIs] & [Workflow Automation]\n                     â†“\n        [Feedback & Continuous Loop]"
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#key-building-blocks",
    "href": "gen-bi-vs-agentic-analytics.html#key-building-blocks",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "7 ğŸ› ï¸ Key Building Blocks",
    "text": "7 ğŸ› ï¸ Key Building Blocks\nâœ… Data Layer: Snowflake, BigQuery, Redshift â€” clean, documented.\nâœ… Semantic Layer: Business-friendly metrics & dimensions (e.g., dbt, AtScale).\nâœ… LLM Integration: Embedded in BI tools (for Gen BI) or orchestrated (for agents).\nâœ… Orchestration Layer: LangChain, AutoGen.\nâœ… Action Layer: API connectors & workflow automation (e.g., Zapier, Airflow)."
  },
  {
    "objectID": "gen-bi-vs-agentic-analytics.html#in-short",
    "href": "gen-bi-vs-agentic-analytics.html#in-short",
    "title": "Generative BI vs.Â Agentic Analytics",
    "section": "8 ğŸ”· In short",
    "text": "8 ğŸ”· In short\n\nGenerative BI = â€œTalk to your data.â€\nAgentic Analytics = â€œYour data solves problems for you.â€\n\n\nIf youâ€™d like, you can also: - ğŸ“„ Add visual diagrams of these architectures. - ğŸš€ Build a tailored roadmap for your organization. - ğŸ“‹ Map these ideas to specific vendors & open-source tools.\nLet me know if youâ€™d like help with any of these!"
  },
  {
    "objectID": "agentic-ai.html",
    "href": "agentic-ai.html",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "",
    "text": "AI systems are gaining autonomy. The latest waveâ€”Agentic AIâ€”doesnâ€™t just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Instead of telling AI what to do at each step, you tell it what outcome you want and let it figure out the path.\nThis shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.\n\n\n\nAgentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they donâ€™t just respond to commandsâ€”they pursue objectives.Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\nTake loan processing as an example. Traditional systems route applications through fixed checkpoints. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the applicationâ€”pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isnâ€™t just scale. Itâ€™s whether the system can navigate complexity without constant human intervention.\n\n\n\n\n\n\n\n\n\nAI Type\nWhat It Does\nKey Limitation\n\n\n\n\nTraditional AI\nExecutes predefined rules or predictions from trained models\nCanâ€™t adapt to tasks outside its training scope\n\n\nGenerative AI\nCreates content (text, images, code) based on learned patterns\nReactive: requires explicit prompts for each step\n\n\nAgentic AI\nPursues goals through multi-step planning and decision-making\nRequires oversight to prevent unintended autonomous actions\n\n\n\nAgentic systems maintain context across interactions (memory), break complex goals into subtasks (planning), access external tools and data sources (tool use), and improve based on outcomes (learning). Earlier AI generations handled these separatelyâ€”or couldnâ€™t do them at all."
  },
  {
    "objectID": "agentic-ai.html#what-is-agentic-ai",
    "href": "agentic-ai.html#what-is-agentic-ai",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "",
    "text": "Agentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they donâ€™t just respond to commandsâ€”they pursue objectives.Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\nTake loan processing as an example. Traditional systems route applications through fixed checkpoints. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the applicationâ€”pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isnâ€™t just scale. Itâ€™s whether the system can navigate complexity without constant human intervention.\n\n\n\n\n\n\n\n\n\nAI Type\nWhat It Does\nKey Limitation\n\n\n\n\nTraditional AI\nExecutes predefined rules or predictions from trained models\nCanâ€™t adapt to tasks outside its training scope\n\n\nGenerative AI\nCreates content (text, images, code) based on learned patterns\nReactive: requires explicit prompts for each step\n\n\nAgentic AI\nPursues goals through multi-step planning and decision-making\nRequires oversight to prevent unintended autonomous actions\n\n\n\nAgentic systems maintain context across interactions (memory), break complex goals into subtasks (planning), access external tools and data sources (tool use), and improve based on outcomes (learning). Earlier AI generations handled these separatelyâ€”or couldnâ€™t do them at all."
  },
  {
    "objectID": "agentic-ai.html#reflection",
    "href": "agentic-ai.html#reflection",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "3.1 Reflection",
    "text": "3.1 Reflection\nAn agent that canâ€™t critique its own output is just automation with extra steps. Reflection lets agents evaluate and improve their outputs before delivering themâ€”the same quality check that humans do.\nResearch shows that even state-of-the-art models like GPT-4 improve their outputs by ~20% through iterative self-feedback.[1] The key is structured evaluation criteriaâ€”specific feedback on what needs improvement drives better refinements than generic critique.\nBest for: Tasks where you need to check and improve quality before delivering. It works well for regulatory reports, customer communications, and compliance documents that have clear quality standards.\n\n\n\nFigure: Reflection lets agents critique and improve their own output before delivering resultsâ€”turning potential errors into learning opportunities.\n\n\nA customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A credit analysis agent might validate whether its risk assessment considered all required factors and whether calculations are correct. Each iteration catches errors that would otherwise reach customers or regulators.\n\nWithout reflection, agents repeat mistakes. With it, they improve with each iteration and maintain the quality standards banking requires."
  },
  {
    "objectID": "agentic-ai.html#tool-use",
    "href": "agentic-ai.html#tool-use",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "3.2 Tool Use",
    "text": "3.2 Tool Use\nAgents without access to external systems are limited to what they learned during training. Tool Use gives agents direct access to your APIs, databases, and systems to ground their actions in current, accurate information.\nResearch demonstrates that LLMs cannot reliably self-verify factual informationâ€”external tools provide the ground truth needed for accurate verification, improving performance by 7-8% points over self-critique alone.2\nBest for: Tasks requiring access to external systems, current information, or specialized capabilities. Essential when agents need to bridge the gap between reasoning and real-world action.\n\n\n\nFigure: A loan processing agent orchestrates multiple systemsâ€”pulling credit data, checking fraud indicators, and updating core bankingâ€”without human coordination.\n\n\nThe agent decides when to use which tool based on task requirements. A loan processing agent might call a credit bureau for credit history, query a fraud detection system for risk indicators, check compliance databases for regulatory requirements, and update the core banking system with the decisionâ€”all without human coordination at each step.\n\nTool use breaks agents free from their training data limitations. Now they can interact with the real systems that run your business."
  },
  {
    "objectID": "agentic-ai.html#planning",
    "href": "agentic-ai.html#planning",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "3.3 Planning",
    "text": "3.3 Planning\nComplex tasks need a plan.. Without planning, agents jump between tasks or skip steps. Planning breaks complex problems into sequencesâ€”agents map the approach before executing.\nBest for: Multi-step problems where order matters and where breaking the problem into phases improves success rates. Essential when tasks have dependencies or when parallel execution can improve efficiency.\n\n\n\nFigure: Agents donâ€™t just follow scriptsâ€”they create plans, execute tasks, evaluate results, and adapt when goals arenâ€™t met.\n\n\nA commercial loan application requires multiple verification steps: document extraction, financial analysis, credit scoring, industry benchmarking, and collateral valuation. Effective planning manages dependenciesâ€”financial analysis canâ€™t begin until documents are extracted, but once complete, credit scoring, benchmarking, and collateral valuation can run in parallel. The agent plans this execution strategy upfront rather than discovering dependencies through trial and error.\n\nPlanning prevents wasted work from executing tasks in the wrong order or repeating steps. In banking, where each verification may involve expensive API calls or human review, planning the optimal execution path saves both time and cost."
  },
  {
    "objectID": "agentic-ai.html#multi-agent-collaboration",
    "href": "agentic-ai.html#multi-agent-collaboration",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "3.4 Multi-Agent Collaboration",
    "text": "3.4 Multi-Agent Collaboration\nSome problems need multiple specialists. No single agent has all the expertise required. The Multi-agent pattern coordinates specialized agents to tackle what individual agents canâ€™t handle alone.\nResearch demonstrates that multi-agent debate significantly improves performance over single agents, with accuracy gains of 7-16% points across reasoning and factuality tasks when agents critique and refine each otherâ€™s outputs.3\nBest for: Complex problems requiring specialized expertise where task decomposition provides clear benefits.\nMulti-agent systems are expensive, high-latency, and difficult to debug. Reserve for tasks where the benefits of specialization clearly outweigh the operational complexity.\n\n\n\nFigure: Complex tasks require specialization. A supervisor agent coordinates specialist agents (market research, content creation, project management) toward a shared objective.\n\n\nTake an example of fraud investigation. One agent analyzes transactions, another checks customer history, a third searches fraud databases. A supervisor coordinates their findings. Each brings different expertise, and together they spot patterns no single agent would miss.\n\nMulti-agent systems work like loan committeesâ€”different specialists bring different expertise. But theyâ€™re expensive to maintain. When something breaks, you might trace through 10-50+ agent calls to find the problem. Donâ€™t go multi-agent unless simpler patterns canâ€™t handle it."
  },
  {
    "objectID": "agentic-ai.html#human-in-the-loop",
    "href": "agentic-ai.html#human-in-the-loop",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "3.5 Human in the Loop",
    "text": "3.5 Human in the Loop\nFor high-stakes decisions, full automation isnâ€™t always appropriateâ€”or legal. Human-in-the-loop lets agents handle analysis and recommendations while humans make final decisions at critical checkpoints. This meets regulatory requirements and still delivers real efficiency gains.\nBest for: High-stakes decisions where errors have serious consequences or regulatory requirements mandate human oversight. Essential when accountability must rest with humans, not algorithms.\n\n\n\nFigure: Agents analyze and recommend, humans review and approve at critical decision points, maintaining accountability while gaining efficiency.\n\n\nLoan approvals, credit limit increases, account closures, fraud confirmations, compliance violationsâ€”any decision that significantly affects a customerâ€™s financial life requires human oversight. Itâ€™s not optional in banking. In many cases, itâ€™s legally required.\nTake loan underwriting. An agent analyzes credit history, calculates risk scores, checks compliance requirements, and recommends approval terms with detailed reasoning. A human underwriter reviews the analysis and makes the final decision. The agent handles the analysis. The human applies judgment and takes responsibility.\nOr fraud investigation. An agent flags suspicious transactions, gathers evidence from multiple systems, and analyzes patterns against known fraud schemes. A human fraud analyst reviews the evidence, considers customer context, and decides whether to block transactions. The agent accelerates investigation. The human prevents false positives that damage customer relationships.\n\nThis isnâ€™t optional in banking. Human-in-the-loop maintains regulatory compliance, preserves accountability, and prevents reputational damage from bad automated decisions. In many cases, itâ€™s legally required."
  },
  {
    "objectID": "agentic-ai.html#quick-selection-guide",
    "href": "agentic-ai.html#quick-selection-guide",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "4.1 Quick Selection Guide",
    "text": "4.1 Quick Selection Guide\n\n\n\n\n\n\n\nTask\nUse This Pattern\n\n\n\n\nPredictable multi-step workflow\nPlanning + Tool Use\n\n\nHigh-stakes decision requiring approval\nPlanning + Human in Loop\n\n\nOutput needs quality control\nReflection + Tool Use\n\n\nRequires specialized expertise\nMulti-Agent (use sparingly)"
  },
  {
    "objectID": "agentic-ai.html#banking-essentials",
    "href": "agentic-ai.html#banking-essentials",
    "title": "Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows",
    "section": "4.2 Banking Essentials",
    "text": "4.2 Banking Essentials\nKeep humans in the loop for loan approvals, fraud confirmations, or anything that affects a customerâ€™s financial life. Build in reflection for regulatory reportsâ€”you need that quality check. And maintain audit trails for every agent decision. Itâ€™s not optional; regulators will ask for them.\n\nBegin with the simplest pattern that might work. Add complexity only when you have clear evidence itâ€™s needed. Multi-agent systems can require analyzing 10â€“50+ LLM calls to debug a single failure. Start with Planning or Routing, add patterns as needed."
  }
]