{"title":"Agentic AI","markdown":{"yaml":{"title":"Agentic AI","format":"html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nArtificial Intelligence (AI) is evolving rapidly, and one of the most exciting developments is the emergence of Agentic AI. Unlike traditional AI systems that simply respond to input, Agentic AI systems can reason, plan, act, and adapt autonomously. This blog post will walk you through the basics of Agentic AI—what it is, how it works, how it differs from other AI approaches, and why it matters.\n\n---\n\n## What Is Agentic AI?\n\n**Agentic AI** refers to intelligent systems that act with intent, autonomy, and adaptability to achieve defined goals. Unlike traditional AI, these agents not only respond to commands but also plan, decide, and act proactively — often without step-by-step human direction.\n\nThey can perceive their environment, break down complex objectives into manageable tasks, interact with tools and APIs, and adapt their behavior based on feedback and context. In essence, they function as proactive collaborators, not just reactive assistants.\n\nGoogle Cloud defines agentic AI as systems with memory, planning, and tool-use capabilities, operating in dynamic feedback loops. IBM and McKinsey emphasize their role as organizational actors — capable of taking initiative, making decisions aligned with goals, and integrating seamlessly with human teams.\n\n\n| **AI Type**       | **Behavior**                               | **Limitation**                         |\n|--------------------|--------------------------------------------|----------------------------------------|\n| **Traditional AI** | Rule-based or ML-based automation          | Rigid, task-specific                   |\n| **Generative AI**  | Generates text, images, audio, or video using LLMs, diffusion, GANs, etc. | Reactive: one prompt → one response   |\n| **Agentic AI**     | Goal-oriented planning and action          | Proactive, multi-step autonomy        |\n\n\n---\n\n# How Agentic AI Works\n\nAgentic AI follows a systematic process where each step is powered by key capabilities built into the system:\n\n1. **Perceive** — The agent collects and analyzes data from sensors, databases, and digital interfaces using its **memory** to understand the environment and identify key entities or patterns.\n2. **Reason** — Using a **reasoning engine** (often an LLM) and contextual **memory**, the agent formulates plans, decomposes goals, and decides on the best course of action.\n3. **Plan** — Supported by its **planner**, the agent organizes the tasks into a logical sequence to achieve the objective.\n4. **Act** — The agent executes the planned tasks by interacting with external systems and APIs through its **tool use** capabilities.\n5. **Learn** — Through a continuous **feedback loop** and updated **memory**, the agent monitors outcomes, learns from them, and refines its models to improve future performance.\n\nThis integrated view shows how the components are not separate modules, but enablers embedded within the steps of the agent’s workflow, making the system proactive, adaptive, and goal-oriented.\n\n---\n\n# Agentic Design Patterns\n\nAgentic AI systems often rely on recurring patterns to act autonomously and effectively. Here are four foundational design patterns commonly used in agent-based architectures:\n\n- **Reflection**  \n  The agent evaluates its own past actions or decisions to improve future performance. This helps with error correction and adaptive behavior.\n\n- **Tool Use**  \n  The agent leverages external tools or APIs—such as calculators, databases, or search engines—to complete tasks it can’t perform internally.\n\n- **Planning**  \n  The agent formulates a step-by-step plan before acting, especially for complex or multi-step goals. Planning improves coherence and task success.\n\n- **Multi-Agent Collaboration**  \n  Multiple agents coordinate or divide tasks, either cooperatively or competitively, to solve problems more efficiently.\n\nThese patterns are often used in combination to build more powerful, flexible, and context-aware AI systems.\n\n---\n\n# Real-World Use Cases\n\nAgentic AI is already transforming industries, delivering measurable benefits and enabling capabilities beyond traditional and generative AI. Below are illustrative examples and data showing how organizations are adopting and benefiting from these systems.\n\n## Illustrative Example: Loan Origination & Operations\n\nIn financial services, agentic AI systems orchestrate the **loan origination journey end-to-end**, going beyond traditional AI workflows or generative AI insights. These agents:\n- Ingest real-time data from macroeconomic trends, customer behavior, regulatory changes, and sentiment analysis.\n- Assess creditworthiness, adjust pricing, recommend optimal product bundles, and flag anomalies for human review.\n- Collaborate with other agents in fraud detection, compliance, and capital allocation to optimize outcomes.\n\nIn operations and customer service, agents dynamically rebalance workloads across call centers, resolve customer inquiries with contextual and emotionally intelligent responses, escalate only when human judgment is needed, and detect emerging patterns (e.g., loan performance divergence) before humans are even aware.\n\nIn multiagent systems, a decentralized network of agents collaborate — one assessing creditworthiness, another modeling risk exposure, and a third ensuring compliance — working together to optimize customer journeys and manage trade-offs in real time.\n\n---\n\n# Key Risks\n\nWith great autonomy comes greater responsibility—and risk.\n\n- **Unintended Autonomy**: Agents may act without proper oversight\n- **Bias and Hallucinations**: Decisions may be based on flawed or biased reasoning\n- **Privacy Concerns**: Tool-using agents must handle sensitive data with care\n- **Brand Consistency**: In customer contexts, inappropriate tone or overpersonalization can damage trust\n\n---\n\n# Risk Management Strategies\n\n- **Bounded Autonomy**: Define task scope and tool permissions\n- **Human-in-the-loop**: Require approvals for high-stakes decisions\n- **Audit Trails**: Log all agent actions for transparency and review\n- **Brand & Tone Governance**: Use tone filters for customer-facing agents\n- **Scenario Testing**: Evaluate agent behavior in simulated environments\n- **Collaborative Governance**: Assign oversight responsibilities to cross-functional teams\n\n---\n\n# Best Practices for Implementation\n\nFrom the *Agentic Artificial Intelligence* book:\n- Start with **pilot programs** in controlled environments\n- Use **hybrid human–AI workflows** to maintain oversight while leveraging automation\n- Scale gradually while building internal support through demonstrated success\n- Encourage agents and employees to learn from each other for continuous improvement\n\n---\n\n# References\n\n1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  \n2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  \n3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  \n4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  \n5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  \n6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  \n7. Bornet, et al. (2024). *Agentic Artificial Intelligence*. Selected pages.","srcMarkdownNoYaml":"\n\n\n# Introduction\n\nArtificial Intelligence (AI) is evolving rapidly, and one of the most exciting developments is the emergence of Agentic AI. Unlike traditional AI systems that simply respond to input, Agentic AI systems can reason, plan, act, and adapt autonomously. This blog post will walk you through the basics of Agentic AI—what it is, how it works, how it differs from other AI approaches, and why it matters.\n\n---\n\n## What Is Agentic AI?\n\n**Agentic AI** refers to intelligent systems that act with intent, autonomy, and adaptability to achieve defined goals. Unlike traditional AI, these agents not only respond to commands but also plan, decide, and act proactively — often without step-by-step human direction.\n\nThey can perceive their environment, break down complex objectives into manageable tasks, interact with tools and APIs, and adapt their behavior based on feedback and context. In essence, they function as proactive collaborators, not just reactive assistants.\n\nGoogle Cloud defines agentic AI as systems with memory, planning, and tool-use capabilities, operating in dynamic feedback loops. IBM and McKinsey emphasize their role as organizational actors — capable of taking initiative, making decisions aligned with goals, and integrating seamlessly with human teams.\n\n\n| **AI Type**       | **Behavior**                               | **Limitation**                         |\n|--------------------|--------------------------------------------|----------------------------------------|\n| **Traditional AI** | Rule-based or ML-based automation          | Rigid, task-specific                   |\n| **Generative AI**  | Generates text, images, audio, or video using LLMs, diffusion, GANs, etc. | Reactive: one prompt → one response   |\n| **Agentic AI**     | Goal-oriented planning and action          | Proactive, multi-step autonomy        |\n\n\n---\n\n# How Agentic AI Works\n\nAgentic AI follows a systematic process where each step is powered by key capabilities built into the system:\n\n1. **Perceive** — The agent collects and analyzes data from sensors, databases, and digital interfaces using its **memory** to understand the environment and identify key entities or patterns.\n2. **Reason** — Using a **reasoning engine** (often an LLM) and contextual **memory**, the agent formulates plans, decomposes goals, and decides on the best course of action.\n3. **Plan** — Supported by its **planner**, the agent organizes the tasks into a logical sequence to achieve the objective.\n4. **Act** — The agent executes the planned tasks by interacting with external systems and APIs through its **tool use** capabilities.\n5. **Learn** — Through a continuous **feedback loop** and updated **memory**, the agent monitors outcomes, learns from them, and refines its models to improve future performance.\n\nThis integrated view shows how the components are not separate modules, but enablers embedded within the steps of the agent’s workflow, making the system proactive, adaptive, and goal-oriented.\n\n---\n\n# Agentic Design Patterns\n\nAgentic AI systems often rely on recurring patterns to act autonomously and effectively. Here are four foundational design patterns commonly used in agent-based architectures:\n\n- **Reflection**  \n  The agent evaluates its own past actions or decisions to improve future performance. This helps with error correction and adaptive behavior.\n\n- **Tool Use**  \n  The agent leverages external tools or APIs—such as calculators, databases, or search engines—to complete tasks it can’t perform internally.\n\n- **Planning**  \n  The agent formulates a step-by-step plan before acting, especially for complex or multi-step goals. Planning improves coherence and task success.\n\n- **Multi-Agent Collaboration**  \n  Multiple agents coordinate or divide tasks, either cooperatively or competitively, to solve problems more efficiently.\n\nThese patterns are often used in combination to build more powerful, flexible, and context-aware AI systems.\n\n---\n\n# Real-World Use Cases\n\nAgentic AI is already transforming industries, delivering measurable benefits and enabling capabilities beyond traditional and generative AI. Below are illustrative examples and data showing how organizations are adopting and benefiting from these systems.\n\n## Illustrative Example: Loan Origination & Operations\n\nIn financial services, agentic AI systems orchestrate the **loan origination journey end-to-end**, going beyond traditional AI workflows or generative AI insights. These agents:\n- Ingest real-time data from macroeconomic trends, customer behavior, regulatory changes, and sentiment analysis.\n- Assess creditworthiness, adjust pricing, recommend optimal product bundles, and flag anomalies for human review.\n- Collaborate with other agents in fraud detection, compliance, and capital allocation to optimize outcomes.\n\nIn operations and customer service, agents dynamically rebalance workloads across call centers, resolve customer inquiries with contextual and emotionally intelligent responses, escalate only when human judgment is needed, and detect emerging patterns (e.g., loan performance divergence) before humans are even aware.\n\nIn multiagent systems, a decentralized network of agents collaborate — one assessing creditworthiness, another modeling risk exposure, and a third ensuring compliance — working together to optimize customer journeys and manage trade-offs in real time.\n\n---\n\n# Key Risks\n\nWith great autonomy comes greater responsibility—and risk.\n\n- **Unintended Autonomy**: Agents may act without proper oversight\n- **Bias and Hallucinations**: Decisions may be based on flawed or biased reasoning\n- **Privacy Concerns**: Tool-using agents must handle sensitive data with care\n- **Brand Consistency**: In customer contexts, inappropriate tone or overpersonalization can damage trust\n\n---\n\n# Risk Management Strategies\n\n- **Bounded Autonomy**: Define task scope and tool permissions\n- **Human-in-the-loop**: Require approvals for high-stakes decisions\n- **Audit Trails**: Log all agent actions for transparency and review\n- **Brand & Tone Governance**: Use tone filters for customer-facing agents\n- **Scenario Testing**: Evaluate agent behavior in simulated environments\n- **Collaborative Governance**: Assign oversight responsibilities to cross-functional teams\n\n---\n\n# Best Practices for Implementation\n\nFrom the *Agentic Artificial Intelligence* book:\n- Start with **pilot programs** in controlled environments\n- Use **hybrid human–AI workflows** to maintain oversight while leveraging automation\n- Scale gradually while building internal support through demonstrated success\n- Encourage agents and employees to learn from each other for continuous improvement\n\n---\n\n# References\n\n1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  \n2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  \n3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  \n4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  \n5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  \n6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  \n7. Bornet, et al. (2024). *Agentic Artificial Intelligence*. Selected pages."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"number-sections":true,"html-math-method":"mathjax","output-file":"agentic-ai.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","title":"Agentic AI"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}