{"title":"Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows","markdown":{"yaml":{"title":"Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows","format":"html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nAI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Instead of telling AI what to do at each step, you tell it what outcome you want and let it figure out the path.\n\nThis shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.\n\n---\n\n## What Is Agentic AI?\n\nAgentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\n> Take loan processing as an example. Traditional systems route applications through fixed checkpoints. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.\n\n\n| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |\n|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|\n| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |\n| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step           |\n| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |\n\nAgentic systems maintain context across interactions (memory), break complex goals into subtasks (planning), access external tools and data sources (tool use), and improve based on outcomes (learning). Earlier AI generations handled these separately—or couldn't do them at all.\n\n---\n\n# How Agentic AI Works\n\nAgentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. The cycle runs continuously, adapting as conditions change.\n\n![**Figure:** Agents operate in a continuous action-feedback loop, using memory and reasoning to interact with external tools and data sources.](images/AgenticAIArchitecture.png)\n\n**Perceive** — The agent pulls data from available sources: databases, APIs, document repositories, or user inputs. It keeps relevant context in memory from past interactions.\n\n**Reason** — A reasoning engine (usually a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. It weighs tradeoffs, anticipates consequences, and selects strategies.\n\n**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. For a loan approval goal, the agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.\n\n**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.\n\n**Learn** — The system captures feedback and adjusts its behavior for next time. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.\n\nEach interaction informs the next. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread.\n\n> These pieces—perception, reasoning, planning, action, learning—work together, not in isolation.\n\n---\n\n# Agentic Design Patterns\n\nAgentic systems rely on core design patterns. Each solves a different problem, and real systems combine them. Understanding these five patterns helps you choose the right architecture for your use case.\n\n## Reflection     \nAn agent that can't critique its own output is just automation with extra steps. Reflection lets agents evaluate and improve their outputs before delivering them—the same quality check that humans do.\n\nResearch shows that even state-of-the-art models like GPT-4 improve their outputs by ~20% through iterative self-feedback.^[1]^ The key is structured evaluation criteria—specific feedback on what needs improvement drives better refinements than generic critique.\n\n**Best for:** Tasks where you need to check and improve quality before delivering. It works well for regulatory reports, customer communications, and compliance documents that have clear quality standards.\n\n![**Figure:** Reflection lets agents critique and improve their own output before delivering results—turning potential errors into learning opportunities.](images/reflection-pattern.png)\n\nA customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A credit analysis agent might validate whether its risk assessment considered all required factors and whether calculations are correct. Each iteration catches errors that would otherwise reach customers or regulators.\n\n> Without reflection, agents repeat mistakes. With it, they improve with each iteration and maintain the quality standards banking requires.\n\n## Tool Use     \nAgents without access to external systems are limited to what they learned during training. Tool Use gives agents direct access to your APIs, databases, and systems to ground their actions in current, accurate information.\n\nResearch demonstrates that LLMs cannot reliably self-verify factual information—external tools provide the ground truth needed for accurate verification, improving performance by 7-8% points over self-critique alone.^2^\n\n**Best for:** Tasks requiring access to external systems, current information, or specialized capabilities. Essential when agents need to bridge the gap between \nreasoning and real-world action.\n\n![**Figure:** A loan processing agent orchestrates multiple systems—pulling credit data, checking fraud indicators, and updating core banking—without human coordination.](images/tooluse-pattern.png)\n\nThe agent decides when to use which tool based on task requirements. A loan processing agent might call a credit bureau for credit history, query a fraud detection system for risk indicators, check compliance databases for regulatory requirements, and update the core banking system with the decision—all without human coordination at each step.\n\n> Tool use breaks agents free from their training data limitations. Now they can interact with the real systems that run your business.\n\n\n## Planning     \nComplex tasks need a plan.. Without planning, agents jump between tasks or skip steps. Planning breaks complex problems into sequences—agents map the approach before executing.\n\n**Best for:** Multi-step problems where order matters and where breaking the problem into phases improves success rates. Essential when tasks have dependencies or when parallel execution can improve efficiency.\n\n![**Figure:** Agents don't just follow scripts—they create plans, execute tasks, evaluate results, and adapt when goals aren't met.](images/PlanningPattern.png)\n\nA commercial loan application requires multiple verification steps: document extraction, financial analysis, credit scoring, industry benchmarking, and collateral valuation. Effective planning manages dependencies—financial analysis can't begin until documents are extracted, but once complete, credit scoring, benchmarking, and collateral valuation can run in parallel. The agent plans this execution strategy upfront rather than discovering dependencies through trial and error.\n\n> Planning prevents wasted work from executing tasks in the wrong order or repeating steps. In banking, where each verification may involve expensive API calls or human review, planning the optimal execution path saves both time and cost.\n\n\n## Multi-Agent Collaboration     \nSome problems need multiple specialists. No single agent has all the expertise required. The Multi-agent pattern coordinates specialized agents to tackle what individual agents can't handle alone.\n\nResearch demonstrates that multi-agent debate significantly improves performance over single agents, with accuracy gains of 7-16% points across reasoning and factuality tasks when agents critique and refine each other's outputs.^3^\n\n**Best for:** Complex problems requiring specialized expertise where task decomposition provides clear benefits.    \n\nMulti-agent systems are expensive, high-latency, and difficult to debug. Reserve for tasks where the benefits of specialization clearly outweigh the operational complexity.\n\n![**Figure:** Complex tasks require specialization. A supervisor agent coordinates specialist agents (market research, content creation, project management) toward a shared objective.](images/multi-agent-pattern.png)\n\nTake an example of fraud investigation. One agent analyzes transactions, another checks customer history, a third searches fraud databases. A supervisor coordinates their findings. Each brings different expertise, and together they spot patterns no single agent would miss.\n\n> Multi-agent systems work like loan committees—different specialists bring different expertise. But they're expensive to maintain. When something breaks, you might trace through 10-50+ agent calls to find the problem. Don't go multi-agent unless simpler patterns can't handle it.\n\n\n## Human in the Loop\nFor high-stakes decisions, full automation isn't always appropriate—or legal. Human-in-the-loop lets agents handle analysis and recommendations while humans make final decisions at critical checkpoints. This meets regulatory requirements and still delivers real efficiency gains.\n\n**Best for:** High-stakes decisions where errors have serious consequences or regulatory requirements mandate human oversight. Essential when accountability must rest with humans, not algorithms.\n\n![**Figure:** Agents analyze and recommend, humans review and approve at critical decision points, maintaining accountability while gaining efficiency.](images/human-in-loop-pattern.png)\n\n\nLoan approvals, credit limit increases, account closures, fraud confirmations, compliance violations—any decision that significantly affects a customer's financial life requires human oversight. It's not optional in banking. In many cases, it's legally required.\n\n**Take loan underwriting.** An agent analyzes credit history, calculates risk scores, checks compliance requirements, and recommends approval terms with detailed reasoning. A human underwriter reviews the analysis and makes the final decision. The agent handles the analysis. The human applies judgment and takes responsibility.\n\n**Or fraud investigation.** An agent flags suspicious transactions, gathers evidence from multiple systems, and analyzes patterns against known fraud schemes. A human fraud analyst reviews the evidence, considers customer context, and decides whether to block transactions. The agent accelerates investigation. The human prevents false positives that damage customer relationships.\n\n\n> This isn't optional in banking. Human-in-the-loop maintains regulatory compliance, preserves accountability, and prevents reputational damage from bad automated decisions. In many cases, it's legally required.\n\n\n\n# Pattern Selection with Banking Examples\n\nNot every problem needs full autonomy. Here's how to decide:\n\n## Quick Selection Guide\n\n| **Your Situation**                      | **Use This Pattern**                  | **Banking Example**                                                                 |\n|----------------------------------------|---------------------------------------|--------------------------------------------------------------------------------------|\n| Predictable multi-step workflow        | `Planning + Tool Use`                | Account opening: KYC → credit check → document generation                           |\n| High-stakes decision requiring approval| `Planning + Human in Loop`           | Loan approval: agent analyzes risk, human approves                                  |\n| Output needs quality control           | `Reflection + Tool Use`              | Regulatory reports: draft → self-review → submit                                    |\n| Requires specialized expertise         | `Multi-Agent (use sparingly)`        | Fraud investigation: transaction, history, and threat agents                        |\n| Tasks evolve step by step              | `ReAct + Tool Use`                   | Suspicious activity monitoring: assess → investigate → escalate if needed           |\n\n \n## Banking Essentials   \n- **Human-in-Loop is mandatory** for loan approvals, fraud detection, or any decision affecting customer experience.\n- **Reflection is essential** for regulatory reports and compliance documents—quality checks aren't optional.\n- **Audit trails are required** for every agent decision. Regulators will ask.\n\n> **Start simple.** Use the most basic pattern that solves your problem. Add complexity only with clear evidence it's needed. Multi-agent systems can require tracing 10–50+ LLM calls to debug a single failure—don't go there unless you must.\n\n\n---\n\n# Where Agentic AI Works Today\nOrganizations are already running agentic systems in production:\n\n**Financial Services**    \nMorgan Stanley rolled out AI assistants to 98% of its financial advisor teams. The tools help advisors pull insights from over 70,000 research reports. Document retrieval efficiency jumped from 20% to 80%, and advisors save 30 minutes per client meeting.^7^       \nBNY Mellon launched Eliza, an internal AI platform now used by 96% of its 50,000 employees. The platform has over 100 AI agents handling tasks from payment processing to code repair.<sup>8,9</sup>\n\n> Major efficiency gains in knowledge retrieval; significant time savings on routine tasks.\n\n**Healthcare**     \nMayo Clinic deployed AI documentation assistants to 2,000+ physicians. Nurses save 30 seconds per patient message, adding up to 1,500 hours saved per month across the organization.<sup>10,11</sup>\nMount Sinai rolled out AI copilots that turn physician conversations into clinical notes automatically. The system integrates directly with their medical records.<sup>12</sup>\n\n> Documentation time significantly reduced; clinicians report saving 30 minutes to 2 hours per day.\n\n**Software Development**      \nJM Family built an AI system with specialized agents for requirements gathering, coding, documentation, and quality assurance. A coordinator agent manages the team.<sup>6</sup>\n\n> QA time cut by 60%; requirements cycles dropped from weeks to days.\n\n**Operations** \nFujitsu uses AI agents for sales support and proposal creation via Microsoft's Azure AI Agent Services. Production time for sales proposals dropped 67%.<sup>5,6</sup>\n\n> Dramatic time savings in document creation and customer-facing operations.\n\n# Conclusion\n\nAgents excel at coordination—pulling data from multiple systems, checking compliance, routing tasks. Humans excel at judgment—considering context, weighing tradeoffs, taking responsibility for outcomes. That division works. As the technology improves, agents will handle more of the coordination. But decisions that affect customers' financial lives will still need human judgment.\n\n---\n\n# References\n\n[1] Madaan, A. et al. (2023). SELF-REFINE: Iterative Refinement with Self-Feedback. https://arxiv.org/pdf/2303.17651\n      \n[2] Gou, Z. et. al. (2024) CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. https://arxiv.org/pdf/2305.11738\n\n[3] Du, Y., Li et. al. (2023). Improving Factuality and Reasoning in Language Models through Multiagent Debate. https://arxiv.org/pdf/2305.14325\n \n[4] Yongliang Shen et. al. HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. https://arxiv.org/pdf/2303.17580\n \n[5] Microsoft. (2025). Fujitsu is revolutionizing sales efficiency with Azure AI Agent Service. https://www.microsoft.com/en/customers/story/21885-fujitsu-azure-ai-foundry\n\n[6] Microsoft. (2025). Agent Factory: The new era of agentic AI—common use cases and design patterns. https://azure.microsoft.com/en-us/blog/agent-factory-the-new-era-of-agentic-ai-common-use-cases-and-design-patterns/\n\n[7] Morgan Stanley. (2023-2024). AI @ Morgan Stanley Platform. https://www.morganstanley.com/press-releases/morgan-stanley-research-announces-askresearchgpt\n\n[8] BNY Mellon. (2025). Artificial Intelligence at BNY. https://www.bny.com/corporate/global/en/about-us/technology-innovation/artificial-intelligence.html\n\n[9] PYMNTS. (2025). BNY Says 96% of Employees Use In-House AI Platform. https://www.pymnts.com/news/artificial-intelligence/2025/bny-says-96percent-employees-use-in-house-ai-platform/\n\n[10] Abridge. (2024). Mayo Clinic Expands Use of Abridge AI Platform. https://www.abridge.com/press-release/mayo-clinic-announcement\n\n[11] Epic. (2024). AI for Clinicians: Mayo Clinic Case Study. https://www.epic.com/software/ai-clinicians/\n\n[12] Becker's Hospital Review. (2025). Mount Sinai to roll out Microsoft AI assistant for clinicians. https://www.beckershospitalreview.com/healthcare-information-technology/ai/mount-sinai-to-roll-out-microsoft-ai-assistant-for-clinicians/\n\n","srcMarkdownNoYaml":"\n\n# Introduction\n\nAI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Instead of telling AI what to do at each step, you tell it what outcome you want and let it figure out the path.\n\nThis shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.\n\n---\n\n## What Is Agentic AI?\n\nAgentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\n> Take loan processing as an example. Traditional systems route applications through fixed checkpoints. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.\n\n\n| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |\n|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|\n| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |\n| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step           |\n| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |\n\nAgentic systems maintain context across interactions (memory), break complex goals into subtasks (planning), access external tools and data sources (tool use), and improve based on outcomes (learning). Earlier AI generations handled these separately—or couldn't do them at all.\n\n---\n\n# How Agentic AI Works\n\nAgentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. The cycle runs continuously, adapting as conditions change.\n\n![**Figure:** Agents operate in a continuous action-feedback loop, using memory and reasoning to interact with external tools and data sources.](images/AgenticAIArchitecture.png)\n\n**Perceive** — The agent pulls data from available sources: databases, APIs, document repositories, or user inputs. It keeps relevant context in memory from past interactions.\n\n**Reason** — A reasoning engine (usually a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. It weighs tradeoffs, anticipates consequences, and selects strategies.\n\n**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. For a loan approval goal, the agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.\n\n**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.\n\n**Learn** — The system captures feedback and adjusts its behavior for next time. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.\n\nEach interaction informs the next. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread.\n\n> These pieces—perception, reasoning, planning, action, learning—work together, not in isolation.\n\n---\n\n# Agentic Design Patterns\n\nAgentic systems rely on core design patterns. Each solves a different problem, and real systems combine them. Understanding these five patterns helps you choose the right architecture for your use case.\n\n## Reflection     \nAn agent that can't critique its own output is just automation with extra steps. Reflection lets agents evaluate and improve their outputs before delivering them—the same quality check that humans do.\n\nResearch shows that even state-of-the-art models like GPT-4 improve their outputs by ~20% through iterative self-feedback.^[1]^ The key is structured evaluation criteria—specific feedback on what needs improvement drives better refinements than generic critique.\n\n**Best for:** Tasks where you need to check and improve quality before delivering. It works well for regulatory reports, customer communications, and compliance documents that have clear quality standards.\n\n![**Figure:** Reflection lets agents critique and improve their own output before delivering results—turning potential errors into learning opportunities.](images/reflection-pattern.png)\n\nA customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A credit analysis agent might validate whether its risk assessment considered all required factors and whether calculations are correct. Each iteration catches errors that would otherwise reach customers or regulators.\n\n> Without reflection, agents repeat mistakes. With it, they improve with each iteration and maintain the quality standards banking requires.\n\n## Tool Use     \nAgents without access to external systems are limited to what they learned during training. Tool Use gives agents direct access to your APIs, databases, and systems to ground their actions in current, accurate information.\n\nResearch demonstrates that LLMs cannot reliably self-verify factual information—external tools provide the ground truth needed for accurate verification, improving performance by 7-8% points over self-critique alone.^2^\n\n**Best for:** Tasks requiring access to external systems, current information, or specialized capabilities. Essential when agents need to bridge the gap between \nreasoning and real-world action.\n\n![**Figure:** A loan processing agent orchestrates multiple systems—pulling credit data, checking fraud indicators, and updating core banking—without human coordination.](images/tooluse-pattern.png)\n\nThe agent decides when to use which tool based on task requirements. A loan processing agent might call a credit bureau for credit history, query a fraud detection system for risk indicators, check compliance databases for regulatory requirements, and update the core banking system with the decision—all without human coordination at each step.\n\n> Tool use breaks agents free from their training data limitations. Now they can interact with the real systems that run your business.\n\n\n## Planning     \nComplex tasks need a plan.. Without planning, agents jump between tasks or skip steps. Planning breaks complex problems into sequences—agents map the approach before executing.\n\n**Best for:** Multi-step problems where order matters and where breaking the problem into phases improves success rates. Essential when tasks have dependencies or when parallel execution can improve efficiency.\n\n![**Figure:** Agents don't just follow scripts—they create plans, execute tasks, evaluate results, and adapt when goals aren't met.](images/PlanningPattern.png)\n\nA commercial loan application requires multiple verification steps: document extraction, financial analysis, credit scoring, industry benchmarking, and collateral valuation. Effective planning manages dependencies—financial analysis can't begin until documents are extracted, but once complete, credit scoring, benchmarking, and collateral valuation can run in parallel. The agent plans this execution strategy upfront rather than discovering dependencies through trial and error.\n\n> Planning prevents wasted work from executing tasks in the wrong order or repeating steps. In banking, where each verification may involve expensive API calls or human review, planning the optimal execution path saves both time and cost.\n\n\n## Multi-Agent Collaboration     \nSome problems need multiple specialists. No single agent has all the expertise required. The Multi-agent pattern coordinates specialized agents to tackle what individual agents can't handle alone.\n\nResearch demonstrates that multi-agent debate significantly improves performance over single agents, with accuracy gains of 7-16% points across reasoning and factuality tasks when agents critique and refine each other's outputs.^3^\n\n**Best for:** Complex problems requiring specialized expertise where task decomposition provides clear benefits.    \n\nMulti-agent systems are expensive, high-latency, and difficult to debug. Reserve for tasks where the benefits of specialization clearly outweigh the operational complexity.\n\n![**Figure:** Complex tasks require specialization. A supervisor agent coordinates specialist agents (market research, content creation, project management) toward a shared objective.](images/multi-agent-pattern.png)\n\nTake an example of fraud investigation. One agent analyzes transactions, another checks customer history, a third searches fraud databases. A supervisor coordinates their findings. Each brings different expertise, and together they spot patterns no single agent would miss.\n\n> Multi-agent systems work like loan committees—different specialists bring different expertise. But they're expensive to maintain. When something breaks, you might trace through 10-50+ agent calls to find the problem. Don't go multi-agent unless simpler patterns can't handle it.\n\n\n## Human in the Loop\nFor high-stakes decisions, full automation isn't always appropriate—or legal. Human-in-the-loop lets agents handle analysis and recommendations while humans make final decisions at critical checkpoints. This meets regulatory requirements and still delivers real efficiency gains.\n\n**Best for:** High-stakes decisions where errors have serious consequences or regulatory requirements mandate human oversight. Essential when accountability must rest with humans, not algorithms.\n\n![**Figure:** Agents analyze and recommend, humans review and approve at critical decision points, maintaining accountability while gaining efficiency.](images/human-in-loop-pattern.png)\n\n\nLoan approvals, credit limit increases, account closures, fraud confirmations, compliance violations—any decision that significantly affects a customer's financial life requires human oversight. It's not optional in banking. In many cases, it's legally required.\n\n**Take loan underwriting.** An agent analyzes credit history, calculates risk scores, checks compliance requirements, and recommends approval terms with detailed reasoning. A human underwriter reviews the analysis and makes the final decision. The agent handles the analysis. The human applies judgment and takes responsibility.\n\n**Or fraud investigation.** An agent flags suspicious transactions, gathers evidence from multiple systems, and analyzes patterns against known fraud schemes. A human fraud analyst reviews the evidence, considers customer context, and decides whether to block transactions. The agent accelerates investigation. The human prevents false positives that damage customer relationships.\n\n\n> This isn't optional in banking. Human-in-the-loop maintains regulatory compliance, preserves accountability, and prevents reputational damage from bad automated decisions. In many cases, it's legally required.\n\n\n\n# Pattern Selection with Banking Examples\n\nNot every problem needs full autonomy. Here's how to decide:\n\n## Quick Selection Guide\n\n| **Your Situation**                      | **Use This Pattern**                  | **Banking Example**                                                                 |\n|----------------------------------------|---------------------------------------|--------------------------------------------------------------------------------------|\n| Predictable multi-step workflow        | `Planning + Tool Use`                | Account opening: KYC → credit check → document generation                           |\n| High-stakes decision requiring approval| `Planning + Human in Loop`           | Loan approval: agent analyzes risk, human approves                                  |\n| Output needs quality control           | `Reflection + Tool Use`              | Regulatory reports: draft → self-review → submit                                    |\n| Requires specialized expertise         | `Multi-Agent (use sparingly)`        | Fraud investigation: transaction, history, and threat agents                        |\n| Tasks evolve step by step              | `ReAct + Tool Use`                   | Suspicious activity monitoring: assess → investigate → escalate if needed           |\n\n \n## Banking Essentials   \n- **Human-in-Loop is mandatory** for loan approvals, fraud detection, or any decision affecting customer experience.\n- **Reflection is essential** for regulatory reports and compliance documents—quality checks aren't optional.\n- **Audit trails are required** for every agent decision. Regulators will ask.\n\n> **Start simple.** Use the most basic pattern that solves your problem. Add complexity only with clear evidence it's needed. Multi-agent systems can require tracing 10–50+ LLM calls to debug a single failure—don't go there unless you must.\n\n\n---\n\n# Where Agentic AI Works Today\nOrganizations are already running agentic systems in production:\n\n**Financial Services**    \nMorgan Stanley rolled out AI assistants to 98% of its financial advisor teams. The tools help advisors pull insights from over 70,000 research reports. Document retrieval efficiency jumped from 20% to 80%, and advisors save 30 minutes per client meeting.^7^       \nBNY Mellon launched Eliza, an internal AI platform now used by 96% of its 50,000 employees. The platform has over 100 AI agents handling tasks from payment processing to code repair.<sup>8,9</sup>\n\n> Major efficiency gains in knowledge retrieval; significant time savings on routine tasks.\n\n**Healthcare**     \nMayo Clinic deployed AI documentation assistants to 2,000+ physicians. Nurses save 30 seconds per patient message, adding up to 1,500 hours saved per month across the organization.<sup>10,11</sup>\nMount Sinai rolled out AI copilots that turn physician conversations into clinical notes automatically. The system integrates directly with their medical records.<sup>12</sup>\n\n> Documentation time significantly reduced; clinicians report saving 30 minutes to 2 hours per day.\n\n**Software Development**      \nJM Family built an AI system with specialized agents for requirements gathering, coding, documentation, and quality assurance. A coordinator agent manages the team.<sup>6</sup>\n\n> QA time cut by 60%; requirements cycles dropped from weeks to days.\n\n**Operations** \nFujitsu uses AI agents for sales support and proposal creation via Microsoft's Azure AI Agent Services. Production time for sales proposals dropped 67%.<sup>5,6</sup>\n\n> Dramatic time savings in document creation and customer-facing operations.\n\n# Conclusion\n\nAgents excel at coordination—pulling data from multiple systems, checking compliance, routing tasks. Humans excel at judgment—considering context, weighing tradeoffs, taking responsibility for outcomes. That division works. As the technology improves, agents will handle more of the coordination. But decisions that affect customers' financial lives will still need human judgment.\n\n---\n\n# References\n\n[1] Madaan, A. et al. (2023). SELF-REFINE: Iterative Refinement with Self-Feedback. https://arxiv.org/pdf/2303.17651\n      \n[2] Gou, Z. et. al. (2024) CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. https://arxiv.org/pdf/2305.11738\n\n[3] Du, Y., Li et. al. (2023). Improving Factuality and Reasoning in Language Models through Multiagent Debate. https://arxiv.org/pdf/2305.14325\n \n[4] Yongliang Shen et. al. HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. https://arxiv.org/pdf/2303.17580\n \n[5] Microsoft. (2025). Fujitsu is revolutionizing sales efficiency with Azure AI Agent Service. https://www.microsoft.com/en/customers/story/21885-fujitsu-azure-ai-foundry\n\n[6] Microsoft. (2025). Agent Factory: The new era of agentic AI—common use cases and design patterns. https://azure.microsoft.com/en-us/blog/agent-factory-the-new-era-of-agentic-ai-common-use-cases-and-design-patterns/\n\n[7] Morgan Stanley. (2023-2024). AI @ Morgan Stanley Platform. https://www.morganstanley.com/press-releases/morgan-stanley-research-announces-askresearchgpt\n\n[8] BNY Mellon. (2025). Artificial Intelligence at BNY. https://www.bny.com/corporate/global/en/about-us/technology-innovation/artificial-intelligence.html\n\n[9] PYMNTS. (2025). BNY Says 96% of Employees Use In-House AI Platform. https://www.pymnts.com/news/artificial-intelligence/2025/bny-says-96percent-employees-use-in-house-ai-platform/\n\n[10] Abridge. (2024). Mayo Clinic Expands Use of Abridge AI Platform. https://www.abridge.com/press-release/mayo-clinic-announcement\n\n[11] Epic. (2024). AI for Clinicians: Mayo Clinic Case Study. https://www.epic.com/software/ai-clinicians/\n\n[12] Becker's Hospital Review. (2025). Mount Sinai to roll out Microsoft AI assistant for clinicians. https://www.beckershospitalreview.com/healthcare-information-technology/ai/mount-sinai-to-roll-out-microsoft-ai-assistant-for-clinicians/\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"number-sections":true,"html-math-method":"mathjax","output-file":"agentic-ai.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","title":"Agentic AI: How Intelligent Agents Will Transform Enterprise Workflows"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}