{"title":"Agentic AI","markdown":{"yaml":{"title":"Agentic AI","format":"html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nAI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Think of the difference between asking someone for directions versus hiring them to get you there. The first requires you to do the work. The second handles the complexity for you.\n\nThis shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.\n\n---\n\n## What Is Agentic AI?\n\nAgentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.\n\nThis difference matters because it changes what you can delegate to AI. Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\n> Consider how a loan application moves through a bank. A traditional system routes the application through fixed decision points. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.\n\n\n| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |\n|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|\n| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |\n| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step          |\n| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |\n\nWhat makes this autonomy possible? Agentic systems combine several capabilities that earlier AI generations handled separately or not at all: maintaining context across interactions (memory), breaking complex goals into subtasks (planning), accessing external tools and data sources (tool use), and improving based on outcomes (learning). Section 3 explains how these capabilities work together in practice.\n\n---\n\n# How Agentic AI Works\n\nUnderstanding what makes a system \"agentic\" is one thing. Seeing how it actually operates is another. Agentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. This isn't a one-time sequence. It's an ongoing loop that adapts as conditions change.\n\n![Agentic AI Architecture. *Source: CS294/194-196: Agentic AI, UC Berkeley (2024).*](images/agentic-ai-architecture.png)\n\n**Perceive** — The agent gathers data from available sources: databases, APIs, document repositories, sensor feeds, or user inputs. Memory systems store relevant context from prior interactions and decisions.\n\n**Reason** — A reasoning engine (typically a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. This isn't simple pattern matching—it involves weighing tradeoffs, anticipating consequences, and selecting strategies.\n\n**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. Consider a loan approval goal. The agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.\n\n**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.\n\n**Learn** — Feedback loops capture outcomes and adjust future behavior. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.\n\nThe cycle repeats continuously. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread. Each iteration informs the next.\n\n---\n\n# Agentic Design Patterns\n\nProduction-grade agentic systems rely on four core design patterns:\n\n![How agentic AI systems reflect, plan, use tools, and collaborate to solve complex tasks.](images/patterns.png)\n\n- **Reflection**: An agent that can't critique its own output is just automation with extra steps. Reflection mechanisms let systems evaluate whether their actions achieved the intended outcome, identify errors in reasoning, and adjust course. A customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A data analysis agent might validate whether its query results actually answer the original question or if it needs to reformulate the approach.\n- **Tool Use**: No model knows everything or can do everything internally. Tool integration extends agent capabilities by connecting to external resources: calculators for precise math, search engines for current information, databases for domain-specific knowledge, code interpreters for computation, and specialized APIs for tasks like image analysis or language translation. The agent decides when to use which tool based on the task requirements.\n- **Planning**: Multi-step goals need structure. Before acting, effective agents map out the required sequence, identify potential obstacles, and establish decision points. A planning-enabled agent doesn't just start executing—it reasons about the problem, develops a strategy, and adapts that strategy as new information becomes available. This is what separates \"following a script\" from \"solving a problem.\"\n- **Multi-Agent Collaboration**: Complex problems often exceed what a single agent can handle efficiently. Multi-agent architectures distribute work across specialized agents that coordinate toward a shared objective. One agent might handle customer communication while another analyzes account history and a third checks fraud indicators. They share context, negotiate priorities, and escalate to human oversight when their combined capabilities hit limits.\n\nMost production deployments combine these patterns. A fraud detection system might use planning to structure its investigation, tool use to query transaction databases and external threat feeds, reflection to validate its confidence in flagged cases, and multi-agent collaboration to coordinate with customer service and compliance systems.\n\n---\n\n# Where Agentic AI Works Today\nAgentic AI is already deployed in production settings:\n\n- **Financial Services**: End-to-end loan processing, fraud detection, portfolio rebalancing, regulatory compliance monitoring, and customer service automation\n- **Healthcare**: Clinical documentation, treatment protocol recommendations, patient monitoring, insurance claims processing, and appointment optimization\n- **Software Development**: Code generation and review, bug diagnosis, test case creation, dependency management, and deployment automation\n- **Customer Operations**: Inquiry resolution, escalation routing, sentiment analysis, proactive outreach, and workload balancing across support teams\n- **Supply Chain**: Demand forecasting, inventory optimization, route planning, vendor negotiation support, and disruption response\n\n---\n\n# References\n\n1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  \n2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  \n3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  \n4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  \n5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  \n6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  \n7. Bornet, et al. (2024). *Agentic Artificial Intelligence*. Selected pages.","srcMarkdownNoYaml":"\n\n# Introduction\n\nAI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Think of the difference between asking someone for directions versus hiring them to get you there. The first requires you to do the work. The second handles the complexity for you.\n\nThis shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.\n\n---\n\n## What Is Agentic AI?\n\nAgentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.\n\nThis difference matters because it changes what you can delegate to AI. Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.\n\n> Consider how a loan application moves through a bank. A traditional system routes the application through fixed decision points. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.\n\n\n| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |\n|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|\n| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |\n| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step          |\n| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |\n\nWhat makes this autonomy possible? Agentic systems combine several capabilities that earlier AI generations handled separately or not at all: maintaining context across interactions (memory), breaking complex goals into subtasks (planning), accessing external tools and data sources (tool use), and improving based on outcomes (learning). Section 3 explains how these capabilities work together in practice.\n\n---\n\n# How Agentic AI Works\n\nUnderstanding what makes a system \"agentic\" is one thing. Seeing how it actually operates is another. Agentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. This isn't a one-time sequence. It's an ongoing loop that adapts as conditions change.\n\n![Agentic AI Architecture. *Source: CS294/194-196: Agentic AI, UC Berkeley (2024).*](images/agentic-ai-architecture.png)\n\n**Perceive** — The agent gathers data from available sources: databases, APIs, document repositories, sensor feeds, or user inputs. Memory systems store relevant context from prior interactions and decisions.\n\n**Reason** — A reasoning engine (typically a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. This isn't simple pattern matching—it involves weighing tradeoffs, anticipating consequences, and selecting strategies.\n\n**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. Consider a loan approval goal. The agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.\n\n**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.\n\n**Learn** — Feedback loops capture outcomes and adjust future behavior. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.\n\nThe cycle repeats continuously. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread. Each iteration informs the next.\n\n---\n\n# Agentic Design Patterns\n\nProduction-grade agentic systems rely on four core design patterns:\n\n![How agentic AI systems reflect, plan, use tools, and collaborate to solve complex tasks.](images/patterns.png)\n\n- **Reflection**: An agent that can't critique its own output is just automation with extra steps. Reflection mechanisms let systems evaluate whether their actions achieved the intended outcome, identify errors in reasoning, and adjust course. A customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A data analysis agent might validate whether its query results actually answer the original question or if it needs to reformulate the approach.\n- **Tool Use**: No model knows everything or can do everything internally. Tool integration extends agent capabilities by connecting to external resources: calculators for precise math, search engines for current information, databases for domain-specific knowledge, code interpreters for computation, and specialized APIs for tasks like image analysis or language translation. The agent decides when to use which tool based on the task requirements.\n- **Planning**: Multi-step goals need structure. Before acting, effective agents map out the required sequence, identify potential obstacles, and establish decision points. A planning-enabled agent doesn't just start executing—it reasons about the problem, develops a strategy, and adapts that strategy as new information becomes available. This is what separates \"following a script\" from \"solving a problem.\"\n- **Multi-Agent Collaboration**: Complex problems often exceed what a single agent can handle efficiently. Multi-agent architectures distribute work across specialized agents that coordinate toward a shared objective. One agent might handle customer communication while another analyzes account history and a third checks fraud indicators. They share context, negotiate priorities, and escalate to human oversight when their combined capabilities hit limits.\n\nMost production deployments combine these patterns. A fraud detection system might use planning to structure its investigation, tool use to query transaction databases and external threat feeds, reflection to validate its confidence in flagged cases, and multi-agent collaboration to coordinate with customer service and compliance systems.\n\n---\n\n# Where Agentic AI Works Today\nAgentic AI is already deployed in production settings:\n\n- **Financial Services**: End-to-end loan processing, fraud detection, portfolio rebalancing, regulatory compliance monitoring, and customer service automation\n- **Healthcare**: Clinical documentation, treatment protocol recommendations, patient monitoring, insurance claims processing, and appointment optimization\n- **Software Development**: Code generation and review, bug diagnosis, test case creation, dependency management, and deployment automation\n- **Customer Operations**: Inquiry resolution, escalation routing, sentiment analysis, proactive outreach, and workload balancing across support teams\n- **Supply Chain**: Demand forecasting, inventory optimization, route planning, vendor negotiation support, and disruption response\n\n---\n\n# References\n\n1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  \n2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  \n3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  \n4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  \n5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  \n6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  \n7. Bornet, et al. (2024). *Agentic Artificial Intelligence*. Selected pages."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"number-sections":true,"html-math-method":"mathjax","output-file":"agentic-ai.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","title":"Agentic AI"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}