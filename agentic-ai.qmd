---
title: "Agentic AI"
format: html
---

# Introduction

AI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Think of the difference between asking someone for directions versus hiring them to get you there. The first requires you to do the work. The second handles the complexity for you.

This shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.

---

## What Is Agentic AI?

Agentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.

Here's why this matters: it changes what you can delegate to AI. Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.

> Consider how a loan application moves through a bank. A traditional system routes applications through fixed decision points. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.


| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |
|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|
| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |
| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step          |
| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |

Agentic systems combine several capabilities that earlier AI generations handled separately or not at all: maintaining context across interactions (memory), breaking complex goals into subtasks (planning), accessing external tools and data sources (tool use), and improving based on outcomes (learning).

---

# How Agentic AI Works

Agentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. The cycle never stops. It adapts as conditions change.

![**Figure:** Agents operate in a continuous action-feedback loop, using memory and reasoning to interact with external tools and data sources.](images/AI-Agents-Architecture.png)

**Perceive** — The agent gathers data from available sources: databases, APIs, document repositories, sensor feeds, or user inputs. Memory systems store relevant context from prior interactions and decisions.

**Reason** — A reasoning engine (typically a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. It weighs tradeoffs, anticipates consequences, and selects strategies.

**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. For a loan approval goal, the agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.

**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.

**Learn** — Feedback loops capture outcomes and adjust future behavior. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.

Each interaction informs the next. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread.

> These capabilities—perception, reasoning, planning, action, learning—don't work in isolation. They're orchestrated through specific design patterns.

---

# Agentic Design Patterns

Agentic systems rely on core design patterns. Each solves a different problem, and real systems combine them.

![How agentic AI systems reflect, plan, use tools, and collaborate to solve complex tasks.](images/AgenticAI-Patterns.png)

## Reflection:     
An agent that can't critique its own output is just automation with extra steps. Reflection pattern enables agents to evaluate and improve their outputs before finalizing them, mimicking how humans review their work.

Research demonstrates that even state-of-the-art models like GPT-4 improve their outputs by ~20% through iterative self-feedback.^[1]^ The key is structured evaluation criteria—specific feedback on what needs improvement drives better refinements than generic critique.

**Best for:** Tasks where you need to check and improve quality before finalizing. It works well for regulatory reports, customer communications, and compliance documents that have clear quality standards.

![**Figure:** Reflection lets agents critique and improve their own output before delivering results—turning potential errors into learning opportunities.](images/reflection-pattern.png)

A customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A credit analysis agent might validate whether its risk assessment considered all required factors and whether calculations are correct. Each iteration catches errors that would otherwise reach customers or regulators.

> **Why this matters:** Without reflection, agents repeat mistakes. With it, they improve with each iteration and maintain the quality standards banking requires.

## Tool Use:     
Agents without access to external systems are limited to what they learned during training. The Tool Use pattern enables agents to interact with APIs, databases, and specialized systems to ground their actions in current, accurate information.

Research demonstrates that LLMs cannot reliably self-verify factual information—external tools provide the ground truth needed for accurate verification, improving performance by 7-8$ points over self-critique alone.^2^

**Best for:** Tasks requiring access to external systems, current information, or specialized capabilities. Essential when agents need to bridge the gap between 
reasoning and real-world action.

![**Figure:** A loan processing agent orchestrates multiple systems—pulling credit data, checking fraud indicators, and updating core banking—without human coordination.](images/tooluse-pattern.png)

The agent decides when to use which tool based on task requirements. A loan processing agent might call a credit bureau for credit history, query a fraud detection system for risk indicators, check compliance databases for regulatory requirements, and update the core banking system with the decision—all without human coordination at each step.

> **Why this matters:** Tool use is how agents break free from their training data limitations and interact with the real systems that run your business.


## Planning:     
Multi-step goals need structure. Before acting, effective agents map out the required sequence, identify potential obstacles, and establish decision points. A planning-enabled agent doesn't just start executing—it reasons about the problem, develops a strategy, and adapts that strategy as new information becomes available.

**Best for:** Complex, multi-step processes with dependencies where the path to completion can be mapped upfront. Most effective for predictable workflows that follow a logical sequence but may need adaptive replanning when steps fail.

![**Figure:** Agents don't just follow scripts—they create plans, execute tasks, evaluate results, and adapt when goals aren't met.](images/PlanningPattern.png)

For a loan approval goal, the agent plans to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one. If identity verification fails, the agent adjusts its plan—perhaps requesting additional documentation or escalating to a human specialist.

> **Why this matters:** This separates "following a script" from "solving a problem." The agent understands why each step matters and what to do when plans fall apart.


## Multi-Agent Collaboration:     
Complex problems often require specialized expertise that no single agent possesses.  Multi-agent architectures coordinate multiple specialized agents—each with distinct capabilities—to solve problems that exceed individual capacity.

Research demonstrates that multi-agent debate significantly improves performance over single agents, with accuracy gains of 7-16 percentage points across reasoning and factuality tasks when agents critique and refine each other's outputs.^3^

**Best for:** Complex problems requiring specialized expertise where task decomposition provides clear benefits. Multi-agent systems are expensive, high-latency, and difficult to debug. Reserve for tasks where the benefits of specialization clearly outweigh the operational complexity.

![**Figure:** Complex tasks require specialization. A supervisor agent coordinates specialist agents (market research, content creation, project management) toward a shared objective.](images/multi-agent-pattern.png)

> **Important:** Multi-agent systems require significant operational investment. Debugging a single failure may require analyzing 10-50+ LLM calls across multiple agents. Start with simpler patterns and add multi-agent architecture only when there's clear evidence it's needed.


## Human in the Loop:
For high-stakes decisions, full automation isn't always appropriate—or legal. Human-in-the-loop architectures let agents handle analysis and recommendations while humans make final decisions at critical checkpoints. This satisfies regulatory requirements while still achieving significant efficiency gains.

**Best for:** High-stakes decisions where errors have serious consequences or regulatory requirements mandate human oversight. Essential when accountability must rest with humans, not algorithms.

![**Figure:** Agents analyze and recommend, humans review and approve at critical decision points, maintaining accountability while gaining efficiency.](images/human-in-loop-pattern.png)


Required in banking: Loan approvals, credit limit increases, account closures, fraud confirmations, compliance violations—any decision that significantly affects a customer's financial life or triggers regulatory scrutiny. A loan underwriting agent might analyze credit history, calculate risk scores, evaluate debt-to-income ratios, check compliance requirements, and recommend approval terms with detailed reasoning. But a human underwriter reviews the analysis and makes the final decision. The agent handles the time-consuming analysis across multiple data sources; the human applies judgment, considers context the model might miss, and takes responsibility for the outcome.
A fraud investigation agent might flag suspicious transactions, gather supporting evidence from multiple systems, analyze patterns against known fraud schemes, and calculate confidence scores. But a human fraud analyst reviews the evidence, considers customer context, and makes the final determination to block transactions or contact the customer. The agent accelerates investigation; the human prevents false positives that damage customer relationships.

> **Why this matters:** This pattern is essential for responsible AI deployment in banking. It maintains regulatory compliance, preserves human accountability, and prevents the reputational damage that comes from automated decisions affecting customers' financial lives. It's not just best practice—it's often legally required.

**Real systems combine patterns:** A fraud detection system might use planning to structure its investigation, tool use to query transaction databases and threat feeds, reflection to validate its confidence in flagged cases, and multi-agent collaboration to coordinate with customer service and compliance systems. The supervisor agent ensures all pieces work together toward accurate fraud detection while maintaining audit trails for regulators.




# Choosing the Right Pattern

Not every problem needs full autonomy. Here's how to decide:

## Quick Selection Guide

| **Your Situation**                                   | **Use This Pattern**                   |
|------------------------------------------------------|----------------------------------------|
| Predictable multi-step workflow                      | Planning + Tool Use                    |
| High-stakes decision requiring approval              | Planning + Human in Loop               |
| Customer service with varied requests                | Routing + Tool Use                     |
| Investigation where each step reveals next action    | ReAct + Tool Use                       |
| Output needs quality control                         | Add Reflection                         |
| Requires specialized expertise                       | Multi-Agent (use sparingly)           |

## Banking Essentials  
**Always include:**

- **Human in Loop** for loan approvals, fraud confirmations, or any decision affecting customer finances  
- **Reflection** for regulatory reports and compliance documents  
- **Audit trails** for all agent decisions (regulatory requirement)  

> **Start Simple: ** Begin with the simplest pattern that might work. Add complexity only when you have clear evidence it's needed. Multi-agent systems can require analyzing 10–50+ LLM calls to debug a single failure. Start with Planning or Routing, add patterns as needed.


---

# Where Agentic AI Works Today
Agentic AI is already deployed in production settings:

**Financial Services** — End-to-end loan processing, fraud detection, regulatory compliance monitoring, and customer service automation. Early adopters report 60-80% time savings in routine workflows and significant cost reductions in manual coordination tasks. 

**Healthcare** — Clinical documentation, treatment protocol recommendations, patient monitoring, and insurance claims processing. Organizations report 67% reduction in documentation time and 80% automation of routine claims processing, with some incident investigations processed for less than $1 per incident.

**Software Development** — Code generation and review, bug diagnosis, test case creation, and deployment automation. Development teams report 60% reduction in QA time and requirements design cycles dropping from **weeks to days.

**Customer Operations** — Inquiry resolution, escalation routing, sentiment analysis, and proactive outreach. Agents handle tier-1 support while humans focus on complex cases requiring judgment and empathy.

> Agents handle structured complexity while humans handle judgment calls. As these systems improve, that boundary will shift, but the principle holds—agents excel at coordinating many moving parts, humans excel at navigating ambiguity and stakeholder relationships.


# Conclusion

Agents handle structured complexity while humans handle judgment calls. As these systems improve, that boundary will shift, but the principle holds—agents excel at coordinating many moving parts, humans excel at navigating ambiguity and stakeholder relationships.

---

# References




[1] Madaan, A. et al. (2023). SELF-REFINE: Iterative Refinement with Self-Feedback. https://arxiv.org/pdf/2303.17651
      
[2] Gou, Z. et. al. (2024) CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. https://arxiv.org/pdf/2305.11738

[3] Du, Y., Li et. al. (2023). Improving Factuality and Reasoning in Language Models through Multiagent Debate. https://arxiv.org/pdf/2305.14325
 



1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  
2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  
3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  
4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  
5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  
6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  
7. Microsoft. 2025. [Fujitsu is revolutionizing sales efficiency with Azure AI Agent Service](https://www.microsoft.com/en/customers/story/21885-fujitsu-azure-ai-foundry)
8. Microsoft. 2025. [Agent Factory: The new era of agentic AI—common use cases and design patterns](https://azure.microsoft.com/en-us/blog/agent-factory-the-new-era-of-agentic-ai-common-use-cases-and-design-patterns/)