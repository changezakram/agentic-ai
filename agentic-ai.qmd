---
title: "Agentic AI"
format: html
---

# Introduction

AI systems are gaining autonomy. The latest wave—Agentic AI—doesn't just answer questions or generate content on command. These systems plan, decide, and act on their own to achieve goals you set. Think of the difference between asking someone for directions versus hiring them to get you there. The first requires you to do the work. The second handles the complexity for you.

This shift from reactive to proactive intelligence changes how organizations can deploy AI. Instead of building workflows around what the model can do in a single interaction, you can assign objectives and let the system figure out how to accomplish them. That capability is already reshaping operations in financial services, healthcare, customer support, and software development.

---

## What Is Agentic AI?

Agentic AI systems act with intent and autonomy to achieve defined goals. The key distinction: they don't just respond to commands—they pursue objectives.

Here's why this matters: it changes what you can delegate to AI. Traditional systems require you to orchestrate each step. Generative systems require you to prompt for each output. Agentic systems let you specify the outcome and trust the system to figure out how to get there.

> Consider how a loan application moves through a bank. A traditional system routes applications through fixed decision points. A generative AI chatbot might answer questions about loan requirements. An agentic system actually processes the application—pulling credit data, verifying employment, calculating risk-adjusted pricing, checking compliance rules, and routing exceptions to human reviewers when needed. The difference isn't just scale. It's whether the system can navigate complexity without constant human intervention.


| **AI Type**       | **What It Does**                                               | **Key Limitation**                                          |
|-------------------|----------------------------------------------------------------|-------------------------------------------------------------|
| Traditional AI    | Executes predefined rules or predictions from trained models   | Can't adapt to tasks outside its training scope             |
| Generative AI     | Creates content (text, images, code) based on learned patterns | Reactive: requires explicit prompts for each step          |
| Agentic AI        | Pursues goals through multi-step planning and decision-making  | Requires oversight to prevent unintended autonomous actions |

Agentic systems combine several capabilities that earlier AI generations handled separately or not at all: maintaining context across interactions (memory), breaking complex goals into subtasks (planning), accessing external tools and data sources (tool use), and improving based on outcomes (learning).

---

# How Agentic AI Works

Agentic systems run in a continuous cycle—perceiving their environment, reasoning about options, planning actions, executing through tools, and learning from results. The cycle never stops. It adapts as conditions change.

![**Figure:** Agents operate in a continuous action-feedback loop, using memory and reasoning to interact with external tools and data sources.](images/AI-Agents-Architecture.png)

**Perceive** — The agent gathers data from available sources: databases, APIs, document repositories, sensor feeds, or user inputs. Memory systems store relevant context from prior interactions and decisions.

**Reason** — A reasoning engine (typically a large language model) analyzes the current state, evaluates options, and determines the best approach given the goal and constraints. It weighs tradeoffs, anticipates consequences, and selects strategies.

**Plan** — The planner breaks complex objectives into discrete tasks, sequences them logically, and identifies dependencies. For a loan approval goal, the agent might plan to: verify identity, pull credit history, calculate debt-to-income ratio, check against underwriting guidelines, and route to human review if red flags emerge. Each step depends on the previous one, and the agent adjusts the sequence if something fails.

**Act** — Tool-use capabilities let the agent execute planned tasks by interacting with external systems. It might call an identity verification API, query a credit bureau database, run a calculation, update a CRM record, or send a notification. The agent chooses which tools to use based on what each step requires.

**Learn** — Feedback loops capture outcomes and adjust future behavior. If a particular sequence of checks consistently flags false positives, the system refines its approach. If certain customer segments respond better to specific communication timing, the agent adapts its strategy.

Each interaction informs the next. A customer service agent might start with a standard response template, detect frustration in the customer's reply, shift to a different communication strategy, pull additional account context, and adjust its tone—all within a single conversation thread.

> These capabilities—perception, reasoning, planning, action, learning—don't work in isolation. They're orchestrated through specific design patterns.

---

# Agentic Design Patterns

Agentic systems rely on four core design patterns. Each solves a different problem, and real systems combine them.

![How agentic AI systems reflect, plan, use tools, and collaborate to solve complex tasks.](images/AgenticAI-Patterns.png)

**Reflection**:     
An agent that can't critique its own output is just automation with extra steps. Reflection mechanisms let systems evaluate whether their actions achieved the intended outcome, identify errors in reasoning, and adjust course. A customer service agent might review its drafted response for tone, clarity, and alignment with brand guidelines before sending. A data analysis agent might validate whether its query results actually answer the original question or if it needs to reformulate the approach. Without reflection, agents repeat mistakes. With it, they improve with each iteration.

![**Figure:** Reflection lets agents critique and improve their own output before delivering results—turning potential errors into learning opportunities.](images/reflection-pattern.png)

**Tool Use**:     
No model knows everything or can do everything internally. Tool integration extends agent capabilities by connecting to external resources: calculators for precise math, search engines for current information, databases for domain-specific knowledge, code interpreters for computation, and specialized APIs for tasks like image analysis or language translation.

![**Figure:** A loan processing agent orchestrates multiple systems—pulling credit data, checking fraud indicators, and updating core banking—without human coordination.](images/tooluse-pattern.png)

The agent decides when to use which tool based on task requirements. This is how agents break free from their training data limitations—they reach out to the world for help.


**Planning**:     
Multi-step goals need structure. Before acting, effective agents map out the required sequence, identify potential obstacles, and establish decision points. A planning-enabled agent doesn't just start executing—it reasons about the problem, develops a strategy, and adapts that strategy as new information becomes available.

![**Figure:** Agents don't just follow scripts—they create plans, execute tasks, evaluate results, and adapt when goals aren't met.](images/PlanningPattern.png)

This separates "following a script" from "solving a problem." The agent doesn't just execute steps—it understands why each step matters and what to do when plans fall apart.


**Multi-Agent Collaboration**:     
Complex problems often exceed what a single agent can handle efficiently. Multi-agent architectures distribute work across specialized agents that coordinate toward a shared objective. One agent might handle customer communication while another analyzes account history and a third checks fraud indicators. They share context, negotiate priorities, and escalate to human oversight when their combined capabilities hit limits.

![**Figure:** Complex tasks require specialization. A supervisor agent coordinates specialist agents (market research, content creation, project management) toward a shared objective.](images/multi-agent-pattern.png)

> Most production deployments combine these patterns. A fraud detection system might use planning to structure its investigation, tool use to query transaction databases and external threat feeds, reflection to validate its confidence in flagged cases, and multi-agent collaboration to coordinate with customer service and compliance systems.


---

# Where Agentic AI Works Today
Agentic AI is already deployed in production settings:

**Financial Services** — End-to-end loan processing, fraud detection, portfolio rebalancing, regulatory compliance monitoring, and customer service automation. Banks are using agents to handle tasks that previously required multiple specialists coordinating across systems.

**Healthcare** — Clinical documentation, treatment protocol recommendations, patient monitoring, insurance claims processing, and appointment optimization. Agents help clinicians spend less time on paperwork and more time with patients.

**Software Development** — Code generation and review, bug diagnosis, test case creation, dependency management, and deployment automation. Development teams use agents to handle routine coding tasks while they focus on architecture and product decisions.

**Customer Operations** — Inquiry resolution, escalation routing, sentiment analysis, proactive outreach, and workload balancing across support teams. Agents handle tier-1 support while humans focus on complex cases requiring judgment and empathy.

**Supply Chain** — Demand forecasting, inventory optimization, route planning, vendor negotiation support, and disruption response. Agents monitor thousands of variables and adjust plans as conditions change.

# Conclusion

Agents handle structured complexity while humans handle judgment calls. As these systems improve, that boundary will shift, but the principle holds—agents excel at coordinating many moving parts, humans excel at navigating ambiguity and stakeholder relationships.

---

# References

1. Google Cloud. (2024). [What are AI agents?](https://cloud.google.com/discover/what-are-ai-agents)  
2. IBM Think. (2024). [What is Agentic AI?](https://www.ibm.com/think/topics/agentic-ai)  
3. IBM Think. (2024). [Agentic AI vs. Generative AI](https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai)  
4. McKinsey & Company. (2024). [When can AI make good decisions? The rise of AI corporate citizens](https://www.mckinsey.com/capabilities/operations/our-insights/when-can-ai-make-good-decisions-the-rise-of-ai-corporate-citizens)  
5. McKinsey & Company. (2024). [The future of work is agentic](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-work-is-agentic)  
6. McKinsey & Company. (2024). [The future of customer experience: Embracing agentic AI](https://www.mckinsey.com/capabilities/operations/our-insights/the-future-of-customer-experience-embracing-agentic-ai)  
7. Bornet, et al. (2024). *Agentic Artificial Intelligence*. Selected pages.